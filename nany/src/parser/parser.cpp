//
//
// Generated by Nany's parser.cpp engine (modified from Kessel's C engine)
//
//


#include <cstdio>
#include <cstdlib>
#include <cwchar>                  // wchar_t
#include <sys/stat.h>
#include <cassert>
#include <iostream>

extern "C"
{
#include "engine.h"                 // The Kessels engine.
#include "grammar.h"                // Generated by GOLD.
} // extern "C"
#include "parser.h"
#include "yuni/yuni.h"
#include "yuni/core/string.h"
#include "../ast/all.h"
#include "../typing/type.h"


#define TRIMREDUCTIONS 0            // 0=off, 1=on




// Forward declaration of generic routine for rule propagation
template<class NodeT = Nany::Ast::Node>
static NodeT* ParseChild(TokenStruct* token, unsigned int index);
// Forward declaration of generic routine for symbol management
static const wchar_t* GetChildSymbol(TokenStruct* token, unsigned int index);



///// Helper subroutines



// Make a readable copy of a string. All characters outside 32...127 are
// displayed as a HEX number in square brackets, for example "[0A]".
static void ReadableString(wchar_t* input, wchar_t* output, long width)
{
	// Sanity check.
	if (!output || !input || (width < 1))
		return;
	output[0] = 0;

	long i1 = 0;
	long i2 = 0;
	while ((i2 < width - 1) && (input[i1] != 0))
	{
		if ((input[i1] >= 32) && (input[i1] <= 127))
		{
			output[i2++] = input[i1];
		}
		else
		{
			if (width - i2 > 4)
			{
				char s1[BUFSIZ];
				sprintf(s1, "%02X", input[i1]);
				output[i2++] = '[';
				output[i2++] = s1[0];
				output[i2++] = s1[1];
				output[i2++] = ']';
			}
		}
		i1++;
	}
	output[i2] = 0;
}




///// Rule subroutines




// <Program> ::= <Unit Declaration> <Dependencies> <Declaration List>
Nany::Ast::Node* Rule_Program(TokenStruct* token)
{
	Nany::Ast::UnitDeclarationNode* unitDecl = ParseChild<Nany::Ast::UnitDeclarationNode>(token, 0);
	Nany::Ast::DeclarationListNode* declarations = ParseChild<Nany::Ast::DeclarationListNode>(token, 2);

	return new Nany::Ast::ProgramNode(unitDecl, declarations);
}




// <Unit Declaration> ::= <Optional Visibility Qualifier> unit Identifier ';'
Nany::Ast::Node* Rule_UnitDeclaration_unit_Identifier_Semi(TokenStruct* token)
{
	// TODO : handle visibility qualifiers

	Nany::Ast::Node* node = new Nany::Ast::UnitDeclarationNode(false, GetChildSymbol(token, 2));
	return node;
}




// <Unit Declaration> ::= 
Nany::Ast::Node* Rule_UnitDeclaration(TokenStruct* token)
{
	return nullptr;
}




// <Dependencies> ::= <Dependency> <Dependencies>
Nany::Ast::Node* Rule_Dependencies(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Dependencies> ::= 
Nany::Ast::Node* Rule_Dependencies2(TokenStruct* token)
{
	return nullptr;
}




// <Dependency> ::= uses Identifier <Dependency Continued> ';'
Nany::Ast::Node* Rule_Dependency_uses_Identifier_Semi(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Dependency Continued> ::= '.' Identifier <Dependency Continued>
Nany::Ast::Node* Rule_DependencyContinued_Dot_Identifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Dependency Continued> ::= 
Nany::Ast::Node* Rule_DependencyContinued(TokenStruct* token)
{
	return nullptr;
}




// <Declaration List> ::= <Function Declaration> <Declaration List>
Nany::Ast::Node* Rule_DeclarationList(TokenStruct* token)
{
	Nany::Ast::FunctionDeclarationNode* funcDecl = ParseChild<Nany::Ast::FunctionDeclarationNode>(token, 0);

	Nany::Ast::DeclarationListNode* declList = ParseChild<Nany::Ast::DeclarationListNode>(token, 1);
	declList->prepend(funcDecl);

	return declList;
}




// <Declaration List> ::= <Class Declaration> <Declaration List>
Nany::Ast::Node* Rule_DeclarationList2(TokenStruct* token)
{
	Nany::Ast::ClassDeclarationNode* classDecl = ParseChild<Nany::Ast::ClassDeclarationNode>(token, 0);

	Nany::Ast::DeclarationListNode* declList = ParseChild<Nany::Ast::DeclarationListNode>(token, 1);
	declList->prepend(classDecl);

	return declList;
}




// <Declaration List> ::= <Workflow Declaration> <Declaration List>
Nany::Ast::Node* Rule_DeclarationList3(TokenStruct* token)
{
	// TODO : Handle workflows

	Nany::Ast::DeclarationListNode* declList = ParseChild<Nany::Ast::DeclarationListNode>(token, 1);
	return declList;
}




// <Declaration List> ::= <Enum Declaration> <Declaration List>
Nany::Ast::Node* Rule_DeclarationList4(TokenStruct* token)
{
	// TODO : Handle enums

	Nany::Ast::DeclarationListNode* declList = ParseChild<Nany::Ast::DeclarationListNode>(token, 1);
	return declList;
}




// <Declaration List> ::= <Typedef> ';' <Declaration List>
Nany::Ast::Node* Rule_DeclarationList_Semi(TokenStruct* token)
{
	Nany::Ast::TypeAliasNode* typeDef = ParseChild<Nany::Ast::TypeAliasNode>(token, 0);

	Nany::Ast::DeclarationListNode* declList = ParseChild<Nany::Ast::DeclarationListNode>(token, 2);
	declList->prepend(typeDef);
	return declList;
}




// <Declaration List> ::= 
Nany::Ast::Node* Rule_DeclarationList5(TokenStruct* token)
{
	return new Nany::Ast::DeclarationListNode();
}




// <Literal> ::= BooleanLiteral
Nany::Ast::Node* Rule_Literal_BooleanLiteral(TokenStruct* token)
{
	const wchar_t* data = GetChildSymbol(token, 0);
	return new Nany::Ast::LiteralNode<bool>(L't' == data[0]);
}




// <Literal> ::= DecLiteral
Nany::Ast::Node* Rule_Literal_DecLiteral(TokenStruct* token)
{
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len];
	wcstombs(buffer, symbol, len);
	Yuni::String data(buffer);
	bool isUnsigned = data[data.size() - 1] == 'u' || (data.size() > 1 && data[data.size() - 2] == 'u')
		|| data[data.size() - 1] == 'U' || (data.size() > 1 && data[data.size() - 2] == 'U');
	if (isUnsigned)
		return new Nany::Ast::LiteralNode<unsigned int>(data.to<unsigned int>());
	else
		return new Nany::Ast::LiteralNode<int>(data.to<int>());
}




// <Literal> ::= HexLiteral
Nany::Ast::Node* Rule_Literal_HexLiteral(TokenStruct* token)
{
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len];
	wcstombs(buffer, symbol, len);
	Yuni::String data(buffer);
	bool isUnsigned = data[data.size() - 1] == 'u' || (data.size() > 1 && data[data.size() - 2] == 'u')
		|| data[data.size() - 1] == 'U' || (data.size() > 1 && data[data.size() - 2] == 'U');
	if (isUnsigned)
		return new Nany::Ast::LiteralNode<unsigned int>(data.to<unsigned int>());
	else
		return new Nany::Ast::LiteralNode<int>(data.to<int>());
}




// <Literal> ::= RealLiteral
Nany::Ast::Node* Rule_Literal_RealLiteral(TokenStruct* token)
{
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;
	Yuni::String data(buffer);
	return new Nany::Ast::LiteralNode<float>(data.to<float>());
}




// <Literal> ::= TimeLiteral
Nany::Ast::Node* Rule_Literal_TimeLiteral(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Literal> ::= CharLiteral
Nany::Ast::Node* Rule_Literal_CharLiteral(TokenStruct* token)
{
	return new Nany::Ast::LiteralNode<wchar_t>(GetChildSymbol(token, 0)[1]);
}




// <Literal> ::= StringLiteral
Nany::Ast::Node* Rule_Literal_StringLiteral(TokenStruct* token)
{
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol) - 2; // Remove the double quotes around the string
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol + 1, len);
	buffer[len] = 0;
	return new Nany::Ast::LiteralNode<const char*>(buffer);
}




// <Literal> ::= BuiltInType
Nany::Ast::Node* Rule_Literal_BuiltInType(TokenStruct* token)
{
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;

	Nany::Typing::Type* typeObject = Nany::Typing::Type::Get(buffer);
	assert(nullptr != typeObject && "Built-in type was not recognized !");

	Nany::Ast::LiteralNode<Nany::Typing::Type*>* literalNode = new Nany::Ast::LiteralNode<Nany::Typing::Type*>(typeObject);
	Nany::Ast::TypeExpressionNode* result = new Nany::Ast::TypeExpressionNode(literalNode);
	result->type(typeObject);
	return result;
}




// <Literal> ::= nil
Nany::Ast::Node* Rule_Literal_nil(TokenStruct* token)
{
	return new Nany::Ast::LiteralNode<void*>(nullptr);
}




// <Literal> ::= self
Nany::Ast::Node* Rule_Literal_self(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Class Declaration> ::= class Identifier <Optional Type Parameters> <Optional Base Classes> <In Block> <Out Block> '{' <Class Content> '}'
Nany::Ast::Node* Rule_ClassDeclaration_class_Identifier_LBrace_RBrace(TokenStruct* token)
{
	Nany::Ast::DeclarationListNode* decls = ParseChild<Nany::Ast::DeclarationListNode>(token, 7);

	// Read the name of the function
	const wchar_t* funcName = GetChildSymbol(token, 1);
	size_t len = wcslen(funcName);
	char* buffer = new char[len + 1];
	wcstombs(buffer, funcName, len);
	buffer[len] = 0;

	return new Nany::Ast::ClassDeclarationNode(buffer, decls);
}




// <Anonymous Class Declaration> ::= class <Optional Type Parameters> <Optional Base Classes> <In Block> <Out Block> '{' <Class Content> '}'
Nany::Ast::Node* Rule_AnonymousClassDeclaration_class_LBrace_RBrace(TokenStruct* token)
{
	Nany::Ast::DeclarationListNode* decls = ParseChild<Nany::Ast::DeclarationListNode>(token, 6);

	// TODO : manage multiple anonymous classes in the same scope
	return new Nany::Ast::ClassDeclarationNode("__anonymous__", decls);
}




// <Optional Base Classes> ::= ':' <SingleThread Exp> <Optional Base Classes Continued>
Nany::Ast::Node* Rule_OptionalBaseClasses_Colon(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_OptionalBaseClasses_Colon: Not yet implemented !");
}




// <Optional Base Classes> ::= 
Nany::Ast::Node* Rule_OptionalBaseClasses(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_OptionalBaseClasses: Not yet implemented !");
}




// <Optional Base Classes Continued> ::= ',' <SingleThread Exp>
Nany::Ast::Node* Rule_OptionalBaseClassesContinued_Comma(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_OptionalBaseClassesContinued_Comma: Not yet implemented !");
}




// <Optional Base Classes Continued> ::= 
Nany::Ast::Node* Rule_OptionalBaseClassesContinued(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_OptionalBaseClassesContinued: Not yet implemented !");
}




// <Class Content> ::= VisibilityQualifier <Class Content>
Nany::Ast::Node* Rule_ClassContent_VisibilityQualifier(TokenStruct* token)
{
	Nany::Ast::DeclarationListNode* decls = ParseChild<Nany::Ast::DeclarationListNode>(token, 1);

	if (!decls)
		decls = new Nany::Ast::DeclarationListNode();

	// Read the name of the function
	const wchar_t* qualifier = GetChildSymbol(token, 0);
	size_t len = wcslen(qualifier);
	char* buffer = new char[len + 1];
	wcstombs(buffer, qualifier, len);
	buffer[len] = 0;

	// Distinguish between the possibilities with minimum effort
	Nany::Ast::VisibilityQualifierNode::VisibilityQualifier enumQualifier =
		Nany::Ast::VisibilityQualifierNode::VisibilityQualifier::vqPublished;
	if (buffer[2] == 'i')
		enumQualifier = Nany::Ast::VisibilityQualifierNode::VisibilityQualifier::vqPrivate;
	else if (buffer[2] == 'o')
		enumQualifier = Nany::Ast::VisibilityQualifierNode::VisibilityQualifier::vqProtected;
	else if (buffer[5] == 'c')
		enumQualifier = Nany::Ast::VisibilityQualifierNode::VisibilityQualifier::vqPublic;

	decls->prepend(new Nany::Ast::VisibilityQualifierNode(enumQualifier));
	return decls;
}




// <Class Content> ::= <Method Declaration> <Class Content>
Nany::Ast::Node* Rule_ClassContent(TokenStruct* token)
{
	Nany::Ast::DeclarationListNode* decls = ParseChild<Nany::Ast::DeclarationListNode>(token, 1);

	if (!decls)
		decls = new Nany::Ast::DeclarationListNode();

	Nany::Ast::MethodDeclarationNode* method = ParseChild<Nany::Ast::MethodDeclarationNode>(token, 0);

	decls->prepend(method);
	return decls;
}




// <Class Content> ::= <Attribute Declaration> ';' <Class Content>
Nany::Ast::Node* Rule_ClassContent_Semi(TokenStruct* token)
{
	Nany::Ast::DeclarationListNode* decls = ParseChild<Nany::Ast::DeclarationListNode>(token, 2);

	if (!decls)
		decls = new Nany::Ast::DeclarationListNode();

	Nany::Ast::AttributeDeclarationNode* attribute = ParseChild<Nany::Ast::AttributeDeclarationNode>(token, 0);

	decls->prepend(attribute);
	return decls;
}




// <Class Content> ::= <Property Declaration> ';' <Class Content>
Nany::Ast::Node* Rule_ClassContent_Semi2(TokenStruct* token)
{
	// TODO : Handle properties

	return ParseChild<Nany::Ast::DeclarationListNode>(token, 2);
}




// <Class Content> ::= <Class Declaration> <Class Content>
Nany::Ast::Node* Rule_ClassContent2(TokenStruct* token)
{
	Nany::Ast::DeclarationListNode* decls = ParseChild<Nany::Ast::DeclarationListNode>(token, 1);

	if (!decls)
		decls = new Nany::Ast::DeclarationListNode();

	Nany::Ast::ClassDeclarationNode* newClass = ParseChild<Nany::Ast::ClassDeclarationNode>(token, 0);

	decls->prepend(newClass);
	return decls;
}




// <Class Content> ::= <Typedef> ';' <Class Content>
Nany::Ast::Node* Rule_ClassContent_Semi3(TokenStruct* token)
{
	Nany::Ast::DeclarationListNode* decls = ParseChild<Nany::Ast::DeclarationListNode>(token, 2);

	if (!decls)
		decls = new Nany::Ast::DeclarationListNode();

	// TODO : class-scoping ?

	Nany::Ast::TypeAliasNode* typeAlias = ParseChild<Nany::Ast::TypeAliasNode>(token, 0);

	decls->prepend(typeAlias);
	return decls;
}




// <Class Content> ::= 
Nany::Ast::Node* Rule_ClassContent3(TokenStruct* token)
{
	return nullptr;
}




// <Property Declaration> ::= property Identifier <Typing> <Assignment> <Property Callbacks>
Nany::Ast::Node* Rule_PropertyDeclaration_property_Identifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Property Declaration> ::= property Identifier <Assignment> <Property Callbacks>
Nany::Ast::Node* Rule_PropertyDeclaration_property_Identifier2(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Property Declaration> ::= property Identifier <Typing> <Property Callbacks>
Nany::Ast::Node* Rule_PropertyDeclaration_property_Identifier3(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Property Callbacks> ::= read <SingleThread Exp> <Property Callbacks>
Nany::Ast::Node* Rule_PropertyCallbacks_read(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Property Callbacks> ::= write <SingleThread Exp> <Property Callbacks>
Nany::Ast::Node* Rule_PropertyCallbacks_write(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Property Callbacks> ::= 
Nany::Ast::Node* Rule_PropertyCallbacks(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Attribute Declaration> ::= attribute Identifier <Typing> <Assignment>
Nany::Ast::Node* Rule_AttributeDeclaration_attribute_Identifier(TokenStruct* token)
{
	// Read the identifier
	const wchar_t* symbol = GetChildSymbol(token, 1);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;

	Nany::Ast::TypeExpressionNode* type = ParseChild<Nany::Ast::TypeExpressionNode>(token, 2);

	Nany::Ast::Node* value = ParseChild<>(token, 3);

	return new Nany::Ast::AttributeDeclarationNode(buffer, type, value);
}




// <Attribute Declaration> ::= attribute Identifier <Assignment>
Nany::Ast::Node* Rule_AttributeDeclaration_attribute_Identifier2(TokenStruct* token)
{
	// Read the identifier
	const wchar_t* symbol = GetChildSymbol(token, 1);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;

	Nany::Ast::Node* value = ParseChild<>(token, 2);

	return new Nany::Ast::AttributeDeclarationNode(buffer, nullptr, value);
}




// <Attribute Declaration> ::= attribute Identifier <Typing>
Nany::Ast::Node* Rule_AttributeDeclaration_attribute_Identifier3(TokenStruct* token)
{
	// Read the identifier
	const wchar_t* symbol = GetChildSymbol(token, 1);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;

	Nany::Ast::TypeExpressionNode* type = ParseChild<Nany::Ast::TypeExpressionNode>(token, 2);

	return new Nany::Ast::AttributeDeclarationNode(buffer, type, nullptr);
}




// <Assignment> ::= ':=' <SingleThread Exp>
Nany::Ast::Node* Rule_Assignment_ColonEq(TokenStruct* token)
{
	return ParseChild<>(token, 1);
}




// <Typing> ::= ':' <Simple Exp>
Nany::Ast::Node* Rule_Typing_Colon(TokenStruct* token)
{
	// TODO : handle qualifiers

	Nany::Ast::Node* expr = ParseChild<>(token, 1);

	Nany::Ast::TypeExpressionNode* typeExpr = dynamic_cast<Nany::Ast::TypeExpressionNode*>(expr);
	if (!typeExpr)
		typeExpr = new Nany::Ast::TypeExpressionNode(expr);
	return typeExpr;
}




// <Typing> ::= ':' <Type Qualifiers> <Typing Continued>
Nany::Ast::Node* Rule_Typing_Colon2(TokenStruct* token)
{
	// TODO : handle qualifiers

	Nany::Ast::Node* expr = ParseChild<>(token, 1);

	Nany::Ast::TypeExpressionNode* typeExpr = dynamic_cast<Nany::Ast::TypeExpressionNode*>(expr);
	if (!typeExpr)
		typeExpr = new Nany::Ast::TypeExpressionNode(expr);
	return typeExpr;
}




// <Typing Continued> ::= <Simple Exp>
Nany::Ast::Node* Rule_TypingContinued(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Typing Continued> ::= 
Nany::Ast::Node* Rule_TypingContinued2(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_TypingContinued2: Not yet implemented !");
}




// <Workflow Declaration> ::= workflow Identifier '{' <Workflow Content> '}'
Nany::Ast::Node* Rule_WorkflowDeclaration_workflow_Identifier_LBrace_RBrace(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Content> ::= <State Block> <Transition Block>
Nany::Ast::Node* Rule_WorkflowContent(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <State Block> ::= states <Workflow States>
Nany::Ast::Node* Rule_StateBlock_states(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <State Block> ::= 
Nany::Ast::Node* Rule_StateBlock(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow States> ::= default Identifier ';' <Workflow States>
Nany::Ast::Node* Rule_WorkflowStates_default_Identifier_Semi(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow States> ::= state Identifier ';' <Workflow States>
Nany::Ast::Node* Rule_WorkflowStates_state_Identifier_Semi(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow States> ::= 
Nany::Ast::Node* Rule_WorkflowStates(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Transition Block> ::= transitions <Workflow Transitions>
Nany::Ast::Node* Rule_TransitionBlock_transitions(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Transition Block> ::= 
Nany::Ast::Node* Rule_TransitionBlock(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Transitions> ::= default allow ';' <Workflow Transitions>
Nany::Ast::Node* Rule_WorkflowTransitions_default_allow_Semi(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Transitions> ::= default forbid ';' <Workflow Transitions>
Nany::Ast::Node* Rule_WorkflowTransitions_default_forbid_Semi(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Transitions> ::= allow <Workflow Permissions> '=>' <Workflow Permissions> ';' <Workflow Transitions>
Nany::Ast::Node* Rule_WorkflowTransitions_allow_EqGt_Semi(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Transitions> ::= forbid <Workflow Permissions> '=>' <Workflow Permissions> ';' <Workflow Transitions>
Nany::Ast::Node* Rule_WorkflowTransitions_forbid_EqGt_Semi(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Transitions> ::= 
Nany::Ast::Node* Rule_WorkflowTransitions(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Permission> ::= '*'
Nany::Ast::Node* Rule_WorkflowPermission_Times(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Permission> ::= Identifier
Nany::Ast::Node* Rule_WorkflowPermission_Identifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Permission> ::= '+' Identifier
Nany::Ast::Node* Rule_WorkflowPermission_Plus_Identifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Permission> ::= '-' Identifier
Nany::Ast::Node* Rule_WorkflowPermission_Minus_Identifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Permissions> ::= <Workflow Permission> ',' <Workflow Permissions>
Nany::Ast::Node* Rule_WorkflowPermissions_Comma(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Workflow Permissions> ::= <Workflow Permission>
Nany::Ast::Node* Rule_WorkflowPermissions(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Enum Declaration> ::= enum Identifier '{' <Enum Content> '}'
Nany::Ast::Node* Rule_EnumDeclaration_enum_Identifier_LBrace_RBrace(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Enum Content> ::= Identifier ',' <Enum Content>
Nany::Ast::Node* Rule_EnumContent_Identifier_Comma(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Enum Content> ::= Identifier
Nany::Ast::Node* Rule_EnumContent_Identifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Enum Content> ::= 
Nany::Ast::Node* Rule_EnumContent(TokenStruct* token)
{
	return nullptr;
}




// <Function Declaration> ::= <Optional Optim Qualifier> function Identifier <Optional Type Parameters> <Optional Parameters> <Return Type Declaration> <In Block> <Out Block> <Function Body>
Nany::Ast::Node* Rule_FunctionDeclaration_function_Identifier(TokenStruct* token)
{
	// Read the parameters
	Nany::Ast::ParameterListNode* params = ParseChild<Nany::Ast::ParameterListNode>(token, 4);

	// TODO : optims, type parameters, in and out blocks

	Nany::Ast::TypeExpressionNode* returnType = ParseChild<Nany::Ast::TypeExpressionNode>(token, 5);

	Nany::Ast::ScopeNode* body = ParseChild<Nany::Ast::ScopeNode>(token, 8);

	// Read the name of the function
	const wchar_t* funcName = GetChildSymbol(token, 2);
	size_t len = wcslen(funcName);
	char* buffer = new char[len + 1];
	wcstombs(buffer, funcName, len);
	buffer[len] = 0;

	return new Nany::Ast::FunctionDeclarationNode(buffer, params, body, returnType);
}




// <Anonymous Function Declaration> ::= <Optional Optim Qualifier> function <Optional Type Parameters> <Optional Parameters> <Return Type Declaration> <In Block> <Out Block> <Function Body>
Nany::Ast::Node* Rule_AnonymousFunctionDeclaration_function(TokenStruct* token)
{
	// Read the parameters
	Nany::Ast::ParameterListNode* params = ParseChild<Nany::Ast::ParameterListNode>(token, 4);

	// TODO : optims, type parameters, in and out blocks

	Nany::Ast::TypeExpressionNode* returnType = ParseChild<Nany::Ast::TypeExpressionNode>(token, 5);

	Nany::Ast::ScopeNode* body = ParseChild<Nany::Ast::ScopeNode>(token, 7);

	// Read the name of the function
	const wchar_t* funcName = GetChildSymbol(token, 2);
	size_t len = wcslen(funcName);
	char* buffer = new char[len + 1];
	wcstombs(buffer, funcName, len);
	buffer[len] = 0;

	return new Nany::Ast::FunctionDeclarationNode(buffer, params, body, returnType);
}




// <Method Declaration> ::= <Optional Optim Qualifier> method Identifier <Optional Type Parameters> <Optional Parameters> <Return Type Declaration> <In Block> <Out Block> <Function Body>
Nany::Ast::Node* Rule_MethodDeclaration_method_Identifier(TokenStruct* token)
{
	// Read the parameters
	Nany::Ast::ParameterListNode* params = ParseChild<Nany::Ast::ParameterListNode>(token, 4);

	// TODO : optims, type parameters, in and out blocks

	Nany::Ast::TypeExpressionNode* returnType = ParseChild<Nany::Ast::TypeExpressionNode>(token, 5);

	Nany::Ast::ScopeNode* body = ParseChild<Nany::Ast::ScopeNode>(token, 8);

	// Read the name of the function
	const wchar_t* funcName = GetChildSymbol(token, 2);
	size_t len = wcslen(funcName);
	char* buffer = new char[len + 1];
	wcstombs(buffer, funcName, len);
	buffer[len] = 0;

	return new Nany::Ast::MethodDeclarationNode(buffer, params, body, returnType, false);
}




// <Method Declaration> ::= <Optional Optim Qualifier> method Identifier <Optional Type Parameters> <Optional Parameters> <Return Type Declaration> <In Block> <Out Block> ';'
Nany::Ast::Node* Rule_MethodDeclaration_method_Identifier_Semi(TokenStruct* token)
{
	// Read the parameters
	Nany::Ast::ParameterListNode* params = ParseChild<Nany::Ast::ParameterListNode>(token, 4);

	// TODO : optims, type parameters, in and out blocks

	Nany::Ast::TypeExpressionNode* returnType = ParseChild<Nany::Ast::TypeExpressionNode>(token, 5);

	// Read the name of the function
	const wchar_t* funcName = GetChildSymbol(token, 2);
	size_t len = wcslen(funcName);
	char* buffer = new char[len + 1];
	wcstombs(buffer, funcName, len);
	buffer[len] = 0;

	return new Nany::Ast::MethodDeclarationNode(buffer, params, nullptr, returnType, true);
}




// <Function Body> ::= '{' <Expression> '}'
Nany::Ast::Node* Rule_FunctionBody_LBrace_RBrace(TokenStruct* token)
{
	return new Nany::Ast::ScopeNode(ParseChild<>(token, 1));
}




// <Function Body> ::= '{' '}'
Nany::Ast::Node* Rule_FunctionBody_LBrace_RBrace2(TokenStruct* token)
{
	return nullptr;
}




// <Return Type Declaration> ::= ':' <Optional Type Qualifiers> <SingleThread Exp>
Nany::Ast::Node* Rule_ReturnTypeDeclaration_Colon(TokenStruct* token)
{
	Nany::Ast::Node* expr = ParseChild<>(token, 2);

	Nany::Ast::TypeExpressionNode* type = dynamic_cast<Nany::Ast::TypeExpressionNode*>(expr);
	if (!type)
		return new Nany::Ast::TypeExpressionNode(expr);
	return type;
}




// <Return Type Declaration> ::= 
Nany::Ast::Node* Rule_ReturnTypeDeclaration(TokenStruct* token)
{
	return nullptr;
}




// <Optional Parameters> ::= '(' <Parameter List> ')'
Nany::Ast::Node* Rule_OptionalParameters_LParan_RParan(TokenStruct* token)
{
	return ParseChild<Nany::Ast::ParameterListNode>(token, 1);
}




// <Optional Parameters> ::= 
Nany::Ast::Node* Rule_OptionalParameters(TokenStruct* token)
{
	return nullptr;
}




// <Parameter List> ::= Identifier <Typing> <Assignment> <Parameter List Continued>
Nany::Ast::Node* Rule_ParameterList_Identifier(TokenStruct* token)
{
	Nany::Ast::ParameterListNode* list = ParseChild<Nany::Ast::ParameterListNode>(token, 3);
	if (!list)
		list = new Nany::Ast::ParameterListNode();

	// Read and convert the identifier
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;
	Nany::Ast::Node* identifier = new Nany::Ast::IdentifierNode(buffer);

	Nany::Ast::TypeExpressionNode* type = ParseChild<Nany::Ast::TypeExpressionNode>(token, 1);
	Nany::Ast::Node* value = ParseChild<>(token, 2);
	Nany::Ast::Node* declaration = new Nany::Ast::VarDeclarationNode(identifier, type);
	Nany::Ast::Node* assignment = new Nany::Ast::AssignmentExpressionNode(declaration, value);
	list->prepend(assignment);
	return list;
}




// <Parameter List> ::= Identifier <Assignment> <Parameter List Continued>
Nany::Ast::Node* Rule_ParameterList_Identifier2(TokenStruct* token)
{
	Nany::Ast::ParameterListNode* list = ParseChild<Nany::Ast::ParameterListNode>(token, 2);
	if (!list)
		list = new Nany::Ast::ParameterListNode();

	// Read and convert the identifier
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;
	Nany::Ast::Node* identifier = new Nany::Ast::IdentifierNode(buffer);

	Nany::Ast::Node* value = ParseChild<>(token, 1);
	Nany::Ast::Node* assignment = new Nany::Ast::AssignmentExpressionNode(identifier, value);
	list->prepend(assignment);
	return list;
}




// <Parameter List> ::= Identifier <Typing> <Parameter List Continued>
Nany::Ast::Node* Rule_ParameterList_Identifier3(TokenStruct* token)
{
	Nany::Ast::ParameterListNode* list = ParseChild<Nany::Ast::ParameterListNode>(token, 2);
	if (!list)
		list = new Nany::Ast::ParameterListNode();

	// Read and convert the identifier
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;
	Nany::Ast::Node* identifier = new Nany::Ast::IdentifierNode(buffer);

	Nany::Ast::TypeExpressionNode* type = ParseChild<Nany::Ast::TypeExpressionNode>(token, 1);
	Nany::Ast::Node* declaration = new Nany::Ast::VarDeclarationNode(identifier, type);
	list->prepend(declaration);
	return list;
}




// <Parameter List> ::= Identifier <Parameter List Continued>
Nany::Ast::Node* Rule_ParameterList_Identifier4(TokenStruct* token)
{
	Nany::Ast::ParameterListNode* list = ParseChild<Nany::Ast::ParameterListNode>(token, 1);
	if (!list)
		list = new Nany::Ast::ParameterListNode();

	// Read and convert the identifier
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;
	Nany::Ast::Node* identifier = new Nany::Ast::IdentifierNode(buffer);

	list->prepend(identifier);
	return list;
}




// <Parameter List> ::= 
Nany::Ast::Node* Rule_ParameterList(TokenStruct* token)
{
	return nullptr;
}




// <Parameter List Continued> ::= ',' <Parameter List>
Nany::Ast::Node* Rule_ParameterListContinued_Comma(TokenStruct* token)
{
	return ParseChild<Nany::Ast::ParameterListNode>(token, 1);
}




// <Parameter List Continued> ::= 
Nany::Ast::Node* Rule_ParameterListContinued(TokenStruct* token)
{
	return nullptr;
}




// <Optional Type Qualifiers> ::= <Type Qualifiers>
Nany::Ast::Node* Rule_OptionalTypeQualifiers(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Optional Type Qualifiers> ::= 
Nany::Ast::Node* Rule_OptionalTypeQualifiers2(TokenStruct* token)
{
	return nullptr;
}




// <Type Qualifiers> ::= TypeQualifier <Type Qualifiers Continued>
Nany::Ast::Node* Rule_TypeQualifiers_TypeQualifier(TokenStruct* token)
{
	Nany::Ast::TypeQualifierListNode* list = ParseChild<Nany::Ast::TypeQualifierListNode>(token, 1);

	if (!list)
		list = new Nany::Ast::TypeQualifierListNode();

	// Read and convert the qualifier
	const wchar_t* qualifier = GetChildSymbol(token, 0);
	size_t len = wcslen(qualifier);
	char* buffer = new char[len + 1];
	wcstombs(buffer, qualifier, len);
	buffer[len] = 0;

	Nany::Ast::TypeQualifierListNode::TypeQualifier tq =
		Nany::Ast::TypeQualifierListNode::TypeQualifier::tqConst;
	if ('r' == buffer[0])
		tq = Nany::Ast::TypeQualifierListNode::TypeQualifier::tqRef;
	else if ('v' == buffer[0])
		tq = Nany::Ast::TypeQualifierListNode::TypeQualifier::tqVolatile;

	list->prepend(tq);
	return list;
}




// <Type Qualifiers Continued> ::= TypeQualifier <Type Qualifiers Continued>
Nany::Ast::Node* Rule_TypeQualifiersContinued_TypeQualifier(TokenStruct* token)
{
	Nany::Ast::TypeQualifierListNode* list = ParseChild<Nany::Ast::TypeQualifierListNode>(token, 1);

	if (!list)
		list = new Nany::Ast::TypeQualifierListNode();

	// Read and convert the qualifier
	const wchar_t* qualifier = GetChildSymbol(token, 0);
	size_t len = wcslen(qualifier);
	char* buffer = new char[len + 1];
	wcstombs(buffer, qualifier, len);
	buffer[len] = 0;

	Nany::Ast::TypeQualifierListNode::TypeQualifier tq =
		Nany::Ast::TypeQualifierListNode::TypeQualifier::tqConst;
	if ('r' == buffer[0])
		tq = Nany::Ast::TypeQualifierListNode::TypeQualifier::tqRef;
	else if ('v' == buffer[0])
		tq = Nany::Ast::TypeQualifierListNode::TypeQualifier::tqVolatile;

	list->prepend(tq);

	return list;
}




// <Type Qualifiers Continued> ::= 
Nany::Ast::Node* Rule_TypeQualifiersContinued(TokenStruct* token)
{
	return nullptr;
}




// <Optional Optim Qualifier> ::= OptimQualifier
Nany::Ast::Node* Rule_OptionalOptimQualifier_OptimQualifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Optional Optim Qualifier> ::= 
Nany::Ast::Node* Rule_OptionalOptimQualifier(TokenStruct* token)
{
	return nullptr;
}




// <Optional Visibility Qualifier> ::= VisibilityQualifier
Nany::Ast::Node* Rule_OptionalVisibilityQualifier_VisibilityQualifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Optional Visibility Qualifier> ::= 
Nany::Ast::Node* Rule_OptionalVisibilityQualifier(TokenStruct* token)
{
	return nullptr;
}




// <Argument List> ::= <Possibly Parallel Exp> <Argument List Continued>
Nany::Ast::Node* Rule_ArgumentList(TokenStruct* token)
{
	Nany::Ast::ArgumentListNode* list = ParseChild<Nany::Ast::ArgumentListNode>(token, 1);
	if (!list)
		list = new Nany::Ast::ArgumentListNode();
	list->prepend(ParseChild<>(token, 0));
	return list;
}




// <Argument List> ::= 
Nany::Ast::Node* Rule_ArgumentList2(TokenStruct* token)
{
	return nullptr;
}




// <Argument List Continued> ::= ',' <Possibly Parallel Exp> <Argument List Continued>
Nany::Ast::Node* Rule_ArgumentListContinued_Comma(TokenStruct* token)
{
	Nany::Ast::ArgumentListNode* list = ParseChild<Nany::Ast::ArgumentListNode>(token, 2);
	if (!list)
		list = new Nany::Ast::ArgumentListNode();
	list->prepend(ParseChild<>(token, 1));
	return list;
}




// <Argument List Continued> ::= 
Nany::Ast::Node* Rule_ArgumentListContinued(TokenStruct* token)
{
	return nullptr;
}




// <Typedef> ::= type Identifier ':=' <Possibly Parallel Exp>
Nany::Ast::Node* Rule_Typedef_type_Identifier_ColonEq(TokenStruct* token)
{
	// Read the identifier
	const wchar_t* symbol = GetChildSymbol(token, 1);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;

	Nany::Ast::TypeExpressionNode* type = ParseChild<Nany::Ast::TypeExpressionNode>(token, 3);

	return new Nany::Ast::TypeAliasNode(buffer, type);
}




// <In Block> ::= in <Expression>
Nany::Ast::Node* Rule_InBlock_in(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <In Block> ::= 
Nany::Ast::Node* Rule_InBlock(TokenStruct* token)
{
	return nullptr;
}




// <Out Block> ::= out <Expression>
Nany::Ast::Node* Rule_OutBlock_out(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Out Block> ::= 
Nany::Ast::Node* Rule_OutBlock(TokenStruct* token)
{
	return nullptr;
}




// <Optional Type Parameters> ::= <Type Parameters>
Nany::Ast::Node* Rule_OptionalTypeParameters(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Optional Type Parameters> ::= 
Nany::Ast::Node* Rule_OptionalTypeParameters2(TokenStruct* token)
{
	return nullptr;
}




// <Type Parameters> ::= '<' Identifier <Type Parameters Continued> '>'
Nany::Ast::Node* Rule_TypeParameters_Lt_Identifier_Gt(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_TypeParameters_Lt_Identifier_Gt: Not yet implemented !");
}




// <Type Parameters> ::= '<' Identifier ':=' <SingleThread Exp> <Type Parameters Continued> '>'
Nany::Ast::Node* Rule_TypeParameters_Lt_Identifier_ColonEq_Gt(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_TypeParameters_Lt_Identifier_ColonEq_Gt: Not yet implemented !");
}




// <Type Parameters Continued> ::= ',' Identifier <Type Parameters Continued>
Nany::Ast::Node* Rule_TypeParametersContinued_Comma_Identifier(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Type Parameters Continued> ::= ',' Identifier ':=' <SingleThread Exp> <Type Parameters Continued>
Nany::Ast::Node* Rule_TypeParametersContinued_Comma_Identifier_ColonEq(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Type Parameters Continued> ::= 
Nany::Ast::Node* Rule_TypeParametersContinued(TokenStruct* token)
{
	return nullptr;
}




// <Type Arguments> ::= <SingleThread Exp> <Type Arguments Continued>
Nany::Ast::Node* Rule_TypeArguments(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_TypeArguments: Not yet implemented !");
}




// <Type Arguments> ::= 
Nany::Ast::Node* Rule_TypeArguments2(TokenStruct* token)
{
	return nullptr;
}




// <Type Arguments Continued> ::= ',' <SingleThread Exp> <Type Parameters Continued>
Nany::Ast::Node* Rule_TypeArgumentsContinued_Comma(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_TypeArgumentsContinued_Comma: Not yet implemented !");
}




// <Type Arguments Continued> ::= 
Nany::Ast::Node* Rule_TypeArgumentsContinued(TokenStruct* token)
{
	return nullptr;
}




// <Expression> ::= <Possibly Parallel Exp> <Expression List>
Nany::Ast::Node* Rule_Expression(TokenStruct* token)
{
	Nany::Ast::Node* expr = ParseChild<>(token, 0);
	Nany::Ast::Node* recursive = ParseChild<>(token, 1);

	if (!recursive)
		return expr;

	Nany::Ast::ExpressionListNode* list = dynamic_cast<Nany::Ast::ExpressionListNode*>(recursive);
	if (!list)
		list = new Nany::Ast::ExpressionListNode();

	list->prepend(expr);
	return list;
}




// <Expression List> ::= ';' <Expression>
Nany::Ast::Node* Rule_ExpressionList_Semi(TokenStruct* token)
{
	Nany::Ast::Node* recursive = ParseChild<>(token, 1);

	Nany::Ast::ExpressionListNode* list = dynamic_cast<Nany::Ast::ExpressionListNode*>(recursive);
	if (!list)
	{
		list = new Nany::Ast::ExpressionListNode();
		list->prepend(recursive);
		return list;
	}
	return recursive;
}




// <Expression List> ::= ';'
Nany::Ast::Node* Rule_ExpressionList_Semi2(TokenStruct* token)
{
	return nullptr;
}




// <Expression List> ::= 
Nany::Ast::Node* Rule_ExpressionList(TokenStruct* token)
{
	return nullptr;
}




// <Possibly Parallel Exp> ::= <SingleThread Exp>
Nany::Ast::Node* Rule_PossiblyParallelExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Possibly Parallel Exp> ::= '&' <SingleThread Exp>
Nany::Ast::Node* Rule_PossiblyParallelExp_Amp(TokenStruct* token)
{
	Nany::Ast::Node* child = ParseChild<>(token, 0);
	return new Nany::Ast::ParallelExpressionNode(child);
}




// <Possibly Parallel Exp> ::= async <SingleThread Exp>
Nany::Ast::Node* Rule_PossiblyParallelExp_async(TokenStruct* token)
{
	Nany::Ast::Node* child = ParseChild<>(token, 0);
	return new Nany::Ast::ParallelExpressionNode(child);
}




// <Possibly Parallel Exp> ::= sync <SingleThread Exp>
Nany::Ast::Node* Rule_PossiblyParallelExp_sync(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <SingleThread Exp> ::= <Assignment Exp>
Nany::Ast::Node* Rule_SingleThreadExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Assignment Exp> ::= <Assignment Exp> ':=' <Is Exp>
Nany::Ast::Node* Rule_AssignmentExp_ColonEq(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);

	return new Nany::Ast::AssignmentExpressionNode(left, right);
}




// <Assignment Exp> ::= <Local Declaration Exp>
Nany::Ast::Node* Rule_AssignmentExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Local Declaration Exp> ::= <Value> <Typing>
Nany::Ast::Node* Rule_LocalDeclarationExp(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::TypeExpressionNode* type = ParseChild<Nany::Ast::TypeExpressionNode>(token, 1);

	return new Nany::Ast::VarDeclarationNode(left, type);
}




// <Local Declaration Exp> ::= <Is Exp>
Nany::Ast::Node* Rule_LocalDeclarationExp2(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Is Exp> ::= <Is Exp> is <Simple Exp>
Nany::Ast::Node* Rule_IsExp_is(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::TypeExpressionNode* right = ParseChild<Nany::Ast::TypeExpressionNode>(token, 2);

	return new Nany::Ast::IsExpressionNode(left, right);
}




// <Is Exp> ::= <Simple Exp>
Nany::Ast::Node* Rule_IsExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Simple Exp> ::= <Binary Exp>
Nany::Ast::Node* Rule_SimpleExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Simple Exp> ::= new <Simple Exp>
Nany::Ast::Node* Rule_SimpleExp_new(TokenStruct* token)
{
	return new Nany::Ast::NewExpressionNode(ParseChild<>(token, 1));
}




// <Simple Exp> ::= <Typedef>
Nany::Ast::Node* Rule_SimpleExp2(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Simple Exp> ::= return <SingleThread Exp>
Nany::Ast::Node* Rule_SimpleExp_return(TokenStruct* token)
{
	return new Nany::Ast::ReturnExpressionNode(ParseChild<>(token, 1));
}




// <Simple Exp> ::= break
Nany::Ast::Node* Rule_SimpleExp_break(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Simple Exp> ::= continue
Nany::Ast::Node* Rule_SimpleExp_continue(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Simple Exp> ::= if <Possibly Parallel Exp> then <Possibly Parallel Exp> <Else Expression>
Nany::Ast::Node* Rule_SimpleExp_if_then(TokenStruct* token)
{
	Nany::Ast::Node* cond = ParseChild<>(token, 1);
	Nany::Ast::Node* thenExpr = ParseChild<>(token, 3);
	Nany::Ast::Node* elseExpr = ParseChild<>(token, 4);

	return new Nany::Ast::IfExpressionNode(cond, thenExpr, elseExpr);
}




// <Simple Exp> ::= while <Possibly Parallel Exp> do <Possibly Parallel Exp>
Nany::Ast::Node* Rule_SimpleExp_while_do(TokenStruct* token)
{
	Nany::Ast::Node* cond = ParseChild<>(token, 1);
	Nany::Ast::Node* expr = ParseChild<>(token, 3);

	return new Nany::Ast::WhileExpressionNode(cond, expr);
}




// <Simple Exp> ::= for Identifier in <Expression> do <Expression>
Nany::Ast::Node* Rule_SimpleExp_for_Identifier_in_do(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Simple Exp> ::= for Identifier in <Expression> order ':' <Expression> packedby ':' <Expression> do <Possibly Parallel Exp>
Nany::Ast::Node* Rule_SimpleExp_for_Identifier_in_order_Colon_packedby_Colon_do(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Simple Exp> ::= for Identifier in <Expression> order do <Expression>
Nany::Ast::Node* Rule_SimpleExp_for_Identifier_in_order_do(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Simple Exp> ::= timeout <Possibly Parallel Exp> do <Expression>
Nany::Ast::Node* Rule_SimpleExp_timeout_do(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Simple Exp> ::= timeout <Possibly Parallel Exp> do <Expression> else <Expression>
Nany::Ast::Node* Rule_SimpleExp_timeout_do_else(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Simple Exp> ::= <Anonymous Function Declaration>
Nany::Ast::Node* Rule_SimpleExp3(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Simple Exp> ::= <Anonymous Class Declaration>
Nany::Ast::Node* Rule_SimpleExp4(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Simple Exp> ::= '{' <Expression> '}'
Nany::Ast::Node* Rule_SimpleExp_LBrace_RBrace(TokenStruct* token)
{
	Nany::Ast::Node* expr = ParseChild<>(token, 1);
	if (nullptr != expr)
		return new Nany::Ast::ScopeNode(expr);
	return nullptr;
}




// <Else Expression> ::= else <Possibly Parallel Exp>
Nany::Ast::Node* Rule_ElseExpression_else(TokenStruct* token)
{
	return ParseChild<>(token, 1);
}




// <Else Expression> ::= 
Nany::Ast::Node* Rule_ElseExpression(TokenStruct* token)
{
	return nullptr;
}




// <Binary Exp> ::= <Binary Exp> '|' <Xor Exp>
Nany::Ast::Node* Rule_BinaryExp_Pipe(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Binary Exp> ::= <Xor Exp>
Nany::Ast::Node* Rule_BinaryExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Xor Exp> ::= <Xor Exp> xor <Or Exp>
Nany::Ast::Node* Rule_XorExp_xor(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Xor Exp> ::= <Or Exp>
Nany::Ast::Node* Rule_XorExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Or Exp> ::= <Or Exp> or <And Exp>
Nany::Ast::Node* Rule_OrExp_or(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Or Exp> ::= <And Exp>
Nany::Ast::Node* Rule_OrExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <And Exp> ::= <And Exp> and <Equal Exp>
Nany::Ast::Node* Rule_AndExp_and(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <And Exp> ::= <Equal Exp>
Nany::Ast::Node* Rule_AndExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Equal Exp> ::= <Equal Exp> '=' <Compare Exp>
Nany::Ast::Node* Rule_EqualExp_Eq(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);
	return new Nany::Ast::EqualExpressionNode(left, right);
}




// <Equal Exp> ::= <Equal Exp> '!=' <Compare Exp>
Nany::Ast::Node* Rule_EqualExp_ExclamEq(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);
	return new Nany::Ast::NotEqualExpressionNode(left, right);
}




// <Equal Exp> ::= <Compare Exp>
Nany::Ast::Node* Rule_EqualExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Compare Exp> ::= <Compare Exp> '<' <Regexp Exp>
Nany::Ast::Node* Rule_CompareExp_Lt(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);
	return new Nany::Ast::InferiorExpressionNode(left, right);
}




// <Compare Exp> ::= <Compare Exp> '>' <Regexp Exp>
Nany::Ast::Node* Rule_CompareExp_Gt(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);
	return new Nany::Ast::SuperiorExpressionNode(left, right);
}




// <Compare Exp> ::= <Compare Exp> '<=' <Regexp Exp>
Nany::Ast::Node* Rule_CompareExp_LtEq(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);
	return new Nany::Ast::InferiorEqualExpressionNode(left, right);
}




// <Compare Exp> ::= <Compare Exp> '>=' <Regexp Exp>
Nany::Ast::Node* Rule_CompareExp_GtEq(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);
	return new Nany::Ast::SuperiorEqualExpressionNode(left, right);
}




// <Compare Exp> ::= <Regexp Exp>
Nany::Ast::Node* Rule_CompareExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Regexp Exp> ::= <Regexp Exp> '~' <Shift Exp>
Nany::Ast::Node* Rule_RegexpExp_Tilde(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");

}




// <Regexp Exp> ::= <Shift Exp>
Nany::Ast::Node* Rule_RegexpExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Shift Exp> ::= <Shift Exp> '<<' <Add Exp>
Nany::Ast::Node* Rule_ShiftExp_LtLt(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Shift Exp> ::= <Shift Exp> '>>' <Add Exp>
Nany::Ast::Node* Rule_ShiftExp_GtGt(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Shift Exp> ::= <Add Exp>
Nany::Ast::Node* Rule_ShiftExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Add Exp> ::= <Add Exp> '+' <Mult Exp>
Nany::Ast::Node* Rule_AddExp_Plus(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);

	return new Nany::Ast::PlusExpressionNode(left, right);
}




// <Add Exp> ::= <Add Exp> '-' <Mult Exp>
Nany::Ast::Node* Rule_AddExp_Minus(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);

	return new Nany::Ast::MinusExpressionNode(left, right);
}




// <Add Exp> ::= <Mult Exp>
Nany::Ast::Node* Rule_AddExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Mult Exp> ::= <Mult Exp> '*' <Power Exp>
Nany::Ast::Node* Rule_MultExp_Times(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);

	return new Nany::Ast::MultiplyExpressionNode(left, right);
}




// <Mult Exp> ::= <Mult Exp> '/' <Power Exp>
Nany::Ast::Node* Rule_MultExp_Div(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);

	return new Nany::Ast::DivideExpressionNode(left, right);
}




// <Mult Exp> ::= <Mult Exp> '%' <Power Exp>
Nany::Ast::Node* Rule_MultExp_Percent(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::Node* right = ParseChild<>(token, 2);

	return new Nany::Ast::ModulusExpressionNode(left, right);
}




// <Mult Exp> ::= <Power Exp>
Nany::Ast::Node* Rule_MultExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Power Exp> ::= <Power Exp> '^' <As Exp>
Nany::Ast::Node* Rule_PowerExp_Caret(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Power Exp> ::= <As Exp>
Nany::Ast::Node* Rule_PowerExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <As Exp> ::= <As Exp> as <Typeof Exp>
Nany::Ast::Node* Rule_AsExp_as(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);
	Nany::Ast::TypeExpressionNode* right = ParseChild<Nany::Ast::TypeExpressionNode>(token, 2);

	return new Nany::Ast::AsExpressionNode(left, right);
}




// <As Exp> ::= <Typeof Exp>
Nany::Ast::Node* Rule_AsExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Typeof Exp> ::= typeof <Negate Exp>
Nany::Ast::Node* Rule_TypeofExp_typeof(TokenStruct* token)
{
	Nany::Ast::Node* expr = ParseChild<>(token, 1);
	Nany::Ast::TypeofExpressionNode* typeOf = new Nany::Ast::TypeofExpressionNode(expr);
	return new Nany::Ast::TypeExpressionNode(typeOf);
}




// <Typeof Exp> ::= <Negate Exp>
Nany::Ast::Node* Rule_TypeofExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Negate Exp> ::= '-' <Value>
Nany::Ast::Node* Rule_NegateExp_Minus(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Negate Exp> ::= -- <Value>
Nany::Ast::Node* Rule_NegateExp_MinusMinus(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Negate Exp> ::= '++' <Value>
Nany::Ast::Node* Rule_NegateExp_PlusPlus(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Negate Exp> ::= <Value> --
Nany::Ast::Node* Rule_NegateExp_MinusMinus2(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Negate Exp> ::= <Value> '++'
Nany::Ast::Node* Rule_NegateExp_PlusPlus2(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Negate Exp> ::= <Value>
Nany::Ast::Node* Rule_NegateExp(TokenStruct* token)
{
	return ParseChild<>(token, 0);
}




// <Value> ::= <Literal> <Subscript>
Nany::Ast::Node* Rule_Value(TokenStruct* token)
{
	// TODO : Handle subscripts on literals
	return ParseChild<>(token, 0);
}




// <Value> ::= '(' <SingleThread Exp> ')' <Subscript>
Nany::Ast::Node* Rule_Value_LParan_RParan(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Value> ::= Identifier <Subscript>
Nany::Ast::Node* Rule_Value_Identifier(TokenStruct* token)
{
	// Read the identifier
	const wchar_t* symbol = GetChildSymbol(token, 0);
	size_t len = wcslen(symbol);
	char* buffer = new char[len + 1];
	wcstombs(buffer, symbol, len);
	buffer[len] = 0;

	// Parse the subscript
	Nany::Ast::Node* subscript = ParseChild<>(token, 1);
	if (subscript)
	{
		Nany::Ast::ArgumentListNode* args = dynamic_cast<Nany::Ast::ArgumentListNode*>(subscript);
		if (!args)
			// TODO: handle other subscripts
			return subscript;
		return new Nany::Ast::FunctionCallNode(buffer, args);
	}

	return new Nany::Ast::IdentifierNode(buffer);
}




// <Value> ::= <Value> '[' ']'
Nany::Ast::Node* Rule_Value_LBracket_RBracket(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);

	Nany::Ast::TypeExpressionNode* type = dynamic_cast<Nany::Ast::TypeExpressionNode*>(left);

	if (type)
	{
		type->type(type->type()->toArrayType());
		return type;
	}

	// TODO
	return left;
}




// <Value> ::= <Value> '[' <SingleThread Exp> ']' <Subscript>
Nany::Ast::Node* Rule_Value_LBracket_RBracket2(TokenStruct* token)
{
	Nany::Ast::Node* left = ParseChild<>(token, 0);

	Nany::Ast::TypeExpressionNode* type = dynamic_cast<Nany::Ast::TypeExpressionNode*>(left);

	if (type)
	{
		Nany::Ast::Node* cardinality = ParseChild<>(token, 2);
		Nany::Ast::LiteralNode<int>* intCard = dynamic_cast<Nany::Ast::LiteralNode<int>*>(cardinality);
		if (intCard)
		{
			type->type(type->type()->toArrayType(/*intCard->data*/));
		}
		else
		{
			Nany::Ast::LiteralNode<unsigned>* uintCard = dynamic_cast<Nany::Ast::LiteralNode<unsigned>*>(cardinality);
			assert(uintCard && "Invalid expression for cardinality in array.");
			type->type(type->type()->toArrayType(/*uintCard->data*/));
		}
		return type;
	}

	// TODO : manage subscript

	// TODO
	return left;
}




// <Value> ::= <Value> '<' <Type Arguments> '>' <Subscript>
Nany::Ast::Node* Rule_Value_Lt_Gt(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_Value_Lt_Gt: Not yet implemented !");
	return nullptr;
}




// <Value> ::= '[' <SingleThread Exp> ']' <Subscript>
Nany::Ast::Node* Rule_Value_LBracket_RBracket3(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Rule_Value_LBracket_RBracket3: Not yet implemented !");
}




// <Subscript> ::= 
Nany::Ast::Node* Rule_Subscript(TokenStruct* token)
{
	return nullptr;
}




// <Subscript> ::= '.' <Value>
Nany::Ast::Node* Rule_Subscript_Dot(TokenStruct* token)
{
	// Not yet implemented !
	assert(false && "Not yet implemented !");
}




// <Subscript> ::= '(' <Argument List> ')'
Nany::Ast::Node* Rule_Subscript_LParan_RParan(TokenStruct* token)
{
	return ParseChild<>(token, 1);
}




///// Rule jumptable




Nany::Ast::Node* (*RuleJumpTable[])(TokenStruct* token) =
{
	// 0. <Program> ::= <Unit Declaration> <Dependencies> <Declaration List>
	Rule_Program,
	// 1. <Unit Declaration> ::= <Optional Visibility Qualifier> unit Identifier ';'
	Rule_UnitDeclaration_unit_Identifier_Semi,
	// 2. <Unit Declaration> ::= 
	Rule_UnitDeclaration,
	// 3. <Dependencies> ::= <Dependency> <Dependencies>
	Rule_Dependencies,
	// 4. <Dependencies> ::= 
	Rule_Dependencies2,
	// 5. <Dependency> ::= uses Identifier <Dependency Continued> ';'
	Rule_Dependency_uses_Identifier_Semi,
	// 6. <Dependency Continued> ::= '.' Identifier <Dependency Continued>
	Rule_DependencyContinued_Dot_Identifier,
	// 7. <Dependency Continued> ::= 
	Rule_DependencyContinued,
	// 8. <Declaration List> ::= <Optional Visibility Qualifier> <Function Declaration> <Declaration List>
	Rule_DeclarationList,
	// 9. <Declaration List> ::= <Optional Visibility Qualifier> <Class Declaration> <Declaration List>
	Rule_DeclarationList2,
	// 10. <Declaration List> ::= <Optional Visibility Qualifier> <Workflow Declaration> <Declaration List>
	Rule_DeclarationList3,
	// 11. <Declaration List> ::= <Optional Visibility Qualifier> <Enum Declaration> <Declaration List>
	Rule_DeclarationList4,
	// 12. <Declaration List> ::= <Optional Visibility Qualifier> <Typedef> ';' <Declaration List>
	Rule_DeclarationList_Semi,
	// 13. <Declaration List> ::= 
	Rule_DeclarationList5,
	// 14. <Literal> ::= BooleanLiteral
	Rule_Literal_BooleanLiteral,
	// 15. <Literal> ::= DecLiteral
	Rule_Literal_DecLiteral,
	// 16. <Literal> ::= HexLiteral
	Rule_Literal_HexLiteral,
	// 17. <Literal> ::= RealLiteral
	Rule_Literal_RealLiteral,
	// 18. <Literal> ::= TimeLiteral
	Rule_Literal_TimeLiteral,
	// 19. <Literal> ::= CharLiteral
	Rule_Literal_CharLiteral,
	// 20. <Literal> ::= StringLiteral
	Rule_Literal_StringLiteral,
	// 21. <Literal> ::= BuiltInType
	Rule_Literal_BuiltInType,
	// 22. <Literal> ::= nil
	Rule_Literal_nil,
	// 23. <Literal> ::= self
	Rule_Literal_self,
	// 24. <Class Declaration> ::= class Identifier <Optional Type Parameters> <Optional Base Classes> <In Block> <Out Block> '{' <Class Content> '}'
	Rule_ClassDeclaration_class_Identifier_LBrace_RBrace,
	// 25. <Anonymous Class Declaration> ::= class <Optional Type Parameters> <Optional Base Classes> <In Block> <Out Block> '{' <Class Content> '}'
	Rule_AnonymousClassDeclaration_class_LBrace_RBrace,
	// 26. <Optional Base Classes> ::= ':' <SingleThread Exp> <Optional Base Classes Continued>
	Rule_OptionalBaseClasses_Colon,
	// 27. <Optional Base Classes> ::= 
	Rule_OptionalBaseClasses,
	// 28. <Optional Base Classes Continued> ::= ',' <SingleThread Exp>
	Rule_OptionalBaseClassesContinued_Comma,
	// 29. <Optional Base Classes Continued> ::= 
	Rule_OptionalBaseClassesContinued,
	// 30. <Class Content> ::= VisibilityQualifier <Class Content>
	Rule_ClassContent_VisibilityQualifier,
	// 31. <Class Content> ::= <Method Declaration> <Class Content>
	Rule_ClassContent,
	// 32. <Class Content> ::= <Attribute Declaration> ';' <Class Content>
	Rule_ClassContent_Semi,
	// 33. <Class Content> ::= <Property Declaration> ';' <Class Content>
	Rule_ClassContent_Semi2,
	// 34. <Class Content> ::= <Class Declaration> <Class Content>
	Rule_ClassContent2,
	// 35. <Class Content> ::= <Typedef> ';' <Class Content>
	Rule_ClassContent_Semi3,
	// 36. <Class Content> ::= 
	Rule_ClassContent3,
	// 37. <Property Declaration> ::= property Identifier <Typing> <Assignment> <Property Callbacks>
	Rule_PropertyDeclaration_property_Identifier,
	// 38. <Property Declaration> ::= property Identifier <Assignment> <Property Callbacks>
	Rule_PropertyDeclaration_property_Identifier2,
	// 39. <Property Declaration> ::= property Identifier <Typing> <Property Callbacks>
	Rule_PropertyDeclaration_property_Identifier3,
	// 40. <Property Callbacks> ::= read <SingleThread Exp> <Property Callbacks>
	Rule_PropertyCallbacks_read,
	// 41. <Property Callbacks> ::= write <SingleThread Exp> <Property Callbacks>
	Rule_PropertyCallbacks_write,
	// 42. <Property Callbacks> ::= 
	Rule_PropertyCallbacks,
	// 43. <Attribute Declaration> ::= attribute Identifier <Typing> <Assignment>
	Rule_AttributeDeclaration_attribute_Identifier,
	// 44. <Attribute Declaration> ::= attribute Identifier <Assignment>
	Rule_AttributeDeclaration_attribute_Identifier2,
	// 45. <Attribute Declaration> ::= attribute Identifier <Typing>
	Rule_AttributeDeclaration_attribute_Identifier3,
	// 46. <Assignment> ::= ':=' <SingleThread Exp>
	Rule_Assignment_ColonEq,
	// 47. <Typing> ::= ':' <Simple Exp>
	Rule_Typing_Colon,
	// 48. <Typing> ::= ':' <Type Qualifiers> <Typing Continued>
	Rule_Typing_Colon2,
	// 49. <Typing Continued> ::= <Simple Exp>
	Rule_TypingContinued,
	// 50. <Typing Continued> ::= 
	Rule_TypingContinued2,
	// 51. <Workflow Declaration> ::= workflow Identifier '{' <Workflow Content> '}'
	Rule_WorkflowDeclaration_workflow_Identifier_LBrace_RBrace,
	// 52. <Workflow Content> ::= <State Block> <Transition Block>
	Rule_WorkflowContent,
	// 53. <State Block> ::= states <Workflow States>
	Rule_StateBlock_states,
	// 54. <State Block> ::= 
	Rule_StateBlock,
	// 55. <Workflow States> ::= default Identifier ';' <Workflow States>
	Rule_WorkflowStates_default_Identifier_Semi,
	// 56. <Workflow States> ::= state Identifier ';' <Workflow States>
	Rule_WorkflowStates_state_Identifier_Semi,
	// 57. <Workflow States> ::= 
	Rule_WorkflowStates,
	// 58. <Transition Block> ::= transitions <Workflow Transitions>
	Rule_TransitionBlock_transitions,
	// 59. <Transition Block> ::= 
	Rule_TransitionBlock,
	// 60. <Workflow Transitions> ::= default allow ';' <Workflow Transitions>
	Rule_WorkflowTransitions_default_allow_Semi,
	// 61. <Workflow Transitions> ::= default forbid ';' <Workflow Transitions>
	Rule_WorkflowTransitions_default_forbid_Semi,
	// 62. <Workflow Transitions> ::= allow <Workflow Permissions> '=>' <Workflow Permissions> ';' <Workflow Transitions>
	Rule_WorkflowTransitions_allow_EqGt_Semi,
	// 63. <Workflow Transitions> ::= forbid <Workflow Permissions> '=>' <Workflow Permissions> ';' <Workflow Transitions>
	Rule_WorkflowTransitions_forbid_EqGt_Semi,
	// 64. <Workflow Transitions> ::= 
	Rule_WorkflowTransitions,
	// 65. <Workflow Permission> ::= '*'
	Rule_WorkflowPermission_Times,
	// 66. <Workflow Permission> ::= Identifier
	Rule_WorkflowPermission_Identifier,
	// 67. <Workflow Permission> ::= '+' Identifier
	Rule_WorkflowPermission_Plus_Identifier,
	// 68. <Workflow Permission> ::= '-' Identifier
	Rule_WorkflowPermission_Minus_Identifier,
	// 69. <Workflow Permissions> ::= <Workflow Permission> ',' <Workflow Permissions>
	Rule_WorkflowPermissions_Comma,
	// 70. <Workflow Permissions> ::= <Workflow Permission>
	Rule_WorkflowPermissions,
	// 71. <Enum Declaration> ::= enum Identifier '{' <Enum Content> '}'
	Rule_EnumDeclaration_enum_Identifier_LBrace_RBrace,
	// 72. <Enum Content> ::= Identifier ',' <Enum Content>
	Rule_EnumContent_Identifier_Comma,
	// 73. <Enum Content> ::= Identifier
	Rule_EnumContent_Identifier,
	// 74. <Enum Content> ::= 
	Rule_EnumContent,
	// 75. <Function Declaration> ::= <Optional Optim Qualifier> function Identifier <Optional Type Parameters> <Optional Parameters> <Return Type Declaration> <In Block> <Out Block> <Function Body>
	Rule_FunctionDeclaration_function_Identifier,
	// 76. <Anonymous Function Declaration> ::= <Optional Optim Qualifier> function <Optional Type Parameters> <Optional Parameters> <Return Type Declaration> <In Block> <Out Block> <Function Body>
	Rule_AnonymousFunctionDeclaration_function,
	// 77. <Method Declaration> ::= <Optional Optim Qualifier> method Identifier <Optional Type Parameters> <Optional Parameters> <Return Type Declaration> <In Block> <Out Block> <Function Body>
	Rule_MethodDeclaration_method_Identifier,
	// 78. <Method Declaration> ::= <Optional Optim Qualifier> method Identifier <Optional Type Parameters> <Optional Parameters> <Return Type Declaration> <In Block> <Out Block> ';'
	Rule_MethodDeclaration_method_Identifier_Semi,
	// 79. <Function Body> ::= '{' <Expression> '}'
	Rule_FunctionBody_LBrace_RBrace,
	// 80. <Function Body> ::= '{' '}'
	Rule_FunctionBody_LBrace_RBrace2,
	// 81. <Return Type Declaration> ::= ':' <Optional Type Qualifiers> <SingleThread Exp>
	Rule_ReturnTypeDeclaration_Colon,
	// 82. <Return Type Declaration> ::= 
	Rule_ReturnTypeDeclaration,
	// 83. <Optional Parameters> ::= '(' <Parameter List> ')'
	Rule_OptionalParameters_LParan_RParan,
	// 84. <Optional Parameters> ::= 
	Rule_OptionalParameters,
	// 85. <Parameter List> ::= Identifier <Typing> <Assignment> <Parameter List Continued>
	Rule_ParameterList_Identifier,
	// 86. <Parameter List> ::= Identifier <Assignment> <Parameter List Continued>
	Rule_ParameterList_Identifier2,
	// 87. <Parameter List> ::= Identifier <Typing> <Parameter List Continued>
	Rule_ParameterList_Identifier3,
	// 88. <Parameter List> ::= Identifier <Parameter List Continued>
	Rule_ParameterList_Identifier4,
	// 89. <Parameter List> ::= 
	Rule_ParameterList,
	// 90. <Parameter List Continued> ::= ',' <Parameter List>
	Rule_ParameterListContinued_Comma,
	// 91. <Parameter List Continued> ::= 
	Rule_ParameterListContinued,
	// 92. <Optional Type Qualifiers> ::= <Type Qualifiers>
	Rule_OptionalTypeQualifiers,
	// 93. <Optional Type Qualifiers> ::= 
	Rule_OptionalTypeQualifiers2,
	// 94. <Type Qualifiers> ::= TypeQualifier <Type Qualifiers Continued>
	Rule_TypeQualifiers_TypeQualifier,
	// 95. <Type Qualifiers Continued> ::= TypeQualifier <Type Qualifiers Continued>
	Rule_TypeQualifiersContinued_TypeQualifier,
	// 96. <Type Qualifiers Continued> ::= 
	Rule_TypeQualifiersContinued,
	// 97. <Optional Optim Qualifier> ::= OptimQualifier
	Rule_OptionalOptimQualifier_OptimQualifier,
	// 98. <Optional Optim Qualifier> ::= 
	Rule_OptionalOptimQualifier,
	// 99. <Optional Visibility Qualifier> ::= VisibilityQualifier
	Rule_OptionalVisibilityQualifier_VisibilityQualifier,
	// 100. <Optional Visibility Qualifier> ::= 
	Rule_OptionalVisibilityQualifier,
	// 101. <Argument List> ::= <Possibly Parallel Exp> <Argument List Continued>
	Rule_ArgumentList,
	// 102. <Argument List> ::= 
	Rule_ArgumentList2,
	// 103. <Argument List Continued> ::= ',' <Possibly Parallel Exp> <Argument List Continued>
	Rule_ArgumentListContinued_Comma,
	// 104. <Argument List Continued> ::= 
	Rule_ArgumentListContinued,
	// 105. <Typedef> ::= type Identifier ':=' <Possibly Parallel Exp>
	Rule_Typedef_type_Identifier_ColonEq,
	// 106. <In Block> ::= in <Expression>
	Rule_InBlock_in,
	// 107. <In Block> ::= 
	Rule_InBlock,
	// 108. <Out Block> ::= out <Expression>
	Rule_OutBlock_out,
	// 109. <Out Block> ::= 
	Rule_OutBlock,
	// 110. <Optional Type Parameters> ::= <Type Parameters>
	Rule_OptionalTypeParameters,
	// 111. <Optional Type Parameters> ::= 
	Rule_OptionalTypeParameters2,
	// 112. <Type Parameters> ::= '<' Identifier <Type Parameters Continued> '>'
	Rule_TypeParameters_Lt_Identifier_Gt,
	// 113. <Type Parameters> ::= '<' Identifier ':=' <SingleThread Exp> <Type Parameters Continued> '>'
	Rule_TypeParameters_Lt_Identifier_ColonEq_Gt,
	// 114. <Type Parameters Continued> ::= ',' Identifier <Type Parameters Continued>
	Rule_TypeParametersContinued_Comma_Identifier,
	// 115. <Type Parameters Continued> ::= ',' Identifier ':=' <SingleThread Exp> <Type Parameters Continued>
	Rule_TypeParametersContinued_Comma_Identifier_ColonEq,
	// 116. <Type Parameters Continued> ::= 
	Rule_TypeParametersContinued,
	// 117. <Type Arguments> ::= <SingleThread Exp> <Type Arguments Continued>
	Rule_TypeArguments,
	// 118. <Type Arguments> ::= 
	Rule_TypeArguments2,
	// 119. <Type Arguments Continued> ::= ',' <SingleThread Exp> <Type Parameters Continued>
	Rule_TypeArgumentsContinued_Comma,
	// 120. <Type Arguments Continued> ::= 
	Rule_TypeArgumentsContinued,
	// 121. <Expression> ::= <Possibly Parallel Exp> <Expression List>
	Rule_Expression,
	// 122. <Expression List> ::= ';' <Expression>
	Rule_ExpressionList_Semi,
	// 123. <Expression List> ::= ';'
	Rule_ExpressionList_Semi2,
	// 124. <Expression List> ::= 
	Rule_ExpressionList,
	// 125. <Possibly Parallel Exp> ::= <SingleThread Exp>
	Rule_PossiblyParallelExp,
	// 126. <Possibly Parallel Exp> ::= '&' <SingleThread Exp>
	Rule_PossiblyParallelExp_Amp,
	// 127. <Possibly Parallel Exp> ::= async <SingleThread Exp>
	Rule_PossiblyParallelExp_async,
	// 128. <Possibly Parallel Exp> ::= sync <SingleThread Exp>
	Rule_PossiblyParallelExp_sync,
	// 129. <SingleThread Exp> ::= <Assignment Exp>
	Rule_SingleThreadExp,
	// 130. <Assignment Exp> ::= <Assignment Exp> ':=' <Is Exp>
	Rule_AssignmentExp_ColonEq,
	// 131. <Assignment Exp> ::= <Local Declaration Exp>
	Rule_AssignmentExp,
	// 132. <Local Declaration Exp> ::= <Value> <Typing>
	Rule_LocalDeclarationExp,
	// 133. <Local Declaration Exp> ::= <Is Exp>
	Rule_LocalDeclarationExp2,
	// 134. <Is Exp> ::= <Is Exp> is <Simple Exp>
	Rule_IsExp_is,
	// 135. <Is Exp> ::= <Simple Exp>
	Rule_IsExp,
	// 136. <Simple Exp> ::= <Binary Exp>
	Rule_SimpleExp,
	// 137. <Simple Exp> ::= new <Simple Exp>
	Rule_SimpleExp_new,
	// 138. <Simple Exp> ::= <Typedef>
	Rule_SimpleExp2,
	// 139. <Simple Exp> ::= return <SingleThread Exp>
	Rule_SimpleExp_return,
	// 140. <Simple Exp> ::= break
	Rule_SimpleExp_break,
	// 141. <Simple Exp> ::= continue
	Rule_SimpleExp_continue,
	// 142. <Simple Exp> ::= if <Possibly Parallel Exp> then <Possibly Parallel Exp> <Else Expression>
	Rule_SimpleExp_if_then,
	// 143. <Simple Exp> ::= while <Possibly Parallel Exp> do <Possibly Parallel Exp>
	Rule_SimpleExp_while_do,
	// 144. <Simple Exp> ::= for Identifier in <Expression> do <Expression>
	Rule_SimpleExp_for_Identifier_in_do,
	// 145. <Simple Exp> ::= for Identifier in <Expression> order ':' <Expression> packedby ':' <Expression> do <Possibly Parallel Exp>
	Rule_SimpleExp_for_Identifier_in_order_Colon_packedby_Colon_do,
	// 146. <Simple Exp> ::= for Identifier in <Expression> order do <Expression>
	Rule_SimpleExp_for_Identifier_in_order_do,
	// 147. <Simple Exp> ::= timeout <Possibly Parallel Exp> do <Expression>
	Rule_SimpleExp_timeout_do,
	// 148. <Simple Exp> ::= timeout <Possibly Parallel Exp> do <Expression> else <Expression>
	Rule_SimpleExp_timeout_do_else,
	// 149. <Simple Exp> ::= <Anonymous Function Declaration>
	Rule_SimpleExp3,
	// 150. <Simple Exp> ::= <Anonymous Class Declaration>
	Rule_SimpleExp4,
	// 151. <Simple Exp> ::= '{' <Expression> '}'
	Rule_SimpleExp_LBrace_RBrace,
	// 152. <Else Expression> ::= else <Possibly Parallel Exp>
	Rule_ElseExpression_else,
	// 153. <Else Expression> ::= 
	Rule_ElseExpression,
	// 154. <Binary Exp> ::= <Binary Exp> '|' <Xor Exp>
	Rule_BinaryExp_Pipe,
	// 155. <Binary Exp> ::= <Xor Exp>
	Rule_BinaryExp,
	// 156. <Xor Exp> ::= <Xor Exp> xor <Or Exp>
	Rule_XorExp_xor,
	// 157. <Xor Exp> ::= <Or Exp>
	Rule_XorExp,
	// 158. <Or Exp> ::= <Or Exp> or <And Exp>
	Rule_OrExp_or,
	// 159. <Or Exp> ::= <And Exp>
	Rule_OrExp,
	// 160. <And Exp> ::= <And Exp> and <Equal Exp>
	Rule_AndExp_and,
	// 161. <And Exp> ::= <Equal Exp>
	Rule_AndExp,
	// 162. <Equal Exp> ::= <Equal Exp> '=' <Compare Exp>
	Rule_EqualExp_Eq,
	// 163. <Equal Exp> ::= <Equal Exp> '!=' <Compare Exp>
	Rule_EqualExp_ExclamEq,
	// 164. <Equal Exp> ::= <Compare Exp>
	Rule_EqualExp,
	// 165. <Compare Exp> ::= <Compare Exp> '<' <Regexp Exp>
	Rule_CompareExp_Lt,
	// 166. <Compare Exp> ::= <Compare Exp> '>' <Regexp Exp>
	Rule_CompareExp_Gt,
	// 167. <Compare Exp> ::= <Compare Exp> '<=' <Regexp Exp>
	Rule_CompareExp_LtEq,
	// 168. <Compare Exp> ::= <Compare Exp> '>=' <Regexp Exp>
	Rule_CompareExp_GtEq,
	// 169. <Compare Exp> ::= <Regexp Exp>
	Rule_CompareExp,
	// 170. <Regexp Exp> ::= <Regexp Exp> '~' <Shift Exp>
	Rule_RegexpExp_Tilde,
	// 171. <Regexp Exp> ::= <Shift Exp>
	Rule_RegexpExp,
	// 172. <Shift Exp> ::= <Shift Exp> '<<' <Add Exp>
	Rule_ShiftExp_LtLt,
	// 173. <Shift Exp> ::= <Shift Exp> '>>' <Add Exp>
	Rule_ShiftExp_GtGt,
	// 174. <Shift Exp> ::= <Add Exp>
	Rule_ShiftExp,
	// 175. <Add Exp> ::= <Add Exp> '+' <Mult Exp>
	Rule_AddExp_Plus,
	// 176. <Add Exp> ::= <Add Exp> '-' <Mult Exp>
	Rule_AddExp_Minus,
	// 177. <Add Exp> ::= <Mult Exp>
	Rule_AddExp,
	// 178. <Mult Exp> ::= <Mult Exp> '*' <Power Exp>
	Rule_MultExp_Times,
	// 179. <Mult Exp> ::= <Mult Exp> '/' <Power Exp>
	Rule_MultExp_Div,
	// 180. <Mult Exp> ::= <Mult Exp> '%' <Power Exp>
	Rule_MultExp_Percent,
	// 181. <Mult Exp> ::= <Power Exp>
	Rule_MultExp,
	// 182. <Power Exp> ::= <Power Exp> '^' <As Exp>
	Rule_PowerExp_Caret,
	// 183. <Power Exp> ::= <As Exp>
	Rule_PowerExp,
	// 184. <As Exp> ::= <As Exp> as <Typeof Exp>
	Rule_AsExp_as,
	// 185. <As Exp> ::= <Typeof Exp>
	Rule_AsExp,
	// 186. <Typeof Exp> ::= typeof <Negate Exp>
	Rule_TypeofExp_typeof,
	// 187. <Typeof Exp> ::= <Negate Exp>
	Rule_TypeofExp,
	// 188. <Negate Exp> ::= '-' <Value>
	Rule_NegateExp_Minus,
	// 189. <Negate Exp> ::= -- <Value>
	Rule_NegateExp_MinusMinus,
	// 190. <Negate Exp> ::= '++' <Value>
	Rule_NegateExp_PlusPlus,
	// 191. <Negate Exp> ::= <Value> --
	Rule_NegateExp_MinusMinus2,
	// 192. <Negate Exp> ::= <Value> '++'
	Rule_NegateExp_PlusPlus2,
	// 193. <Negate Exp> ::= <Value>
	Rule_NegateExp,
	// 194. <Value> ::= <Literal> <Subscript>
	Rule_Value,
	// 195. <Value> ::= '(' <SingleThread Exp> ')' <Subscript>
	Rule_Value_LParan_RParan,
	// 196. <Value> ::= Identifier <Subscript>
	Rule_Value_Identifier,
	// 197. <Value> ::= <Value> '[' ']'
	Rule_Value_LBracket_RBracket,
	// 198. <Value> ::= <Value> '[' <SingleThread Exp> ']' <Subscript>
	Rule_Value_LBracket_RBracket2,
	// 199. <Value> ::= <Value> '<' <Type Arguments> '>' <Subscript>
	Rule_Value_Lt_Gt,
	// 200. <Value> ::= '[' <SingleThread Exp> ']' <Subscript>
	Rule_Value_LBracket_RBracket3,
	// 201. <Subscript> ::= 
	Rule_Subscript,
	// 202. <Subscript> ::= '.' <Value>
	Rule_Subscript_Dot,
	// 203. <Subscript> ::= '(' <Argument List> ')'
	Rule_Subscript_LParan_RParan 
};

///// Rule subroutine template


template<class NodeT = Nany::Ast::Node>
static NodeT* ParseChild(TokenStruct* parent, unsigned int index)
{
	assert(parent && "ParseChild: invalid parent");
	// Make sure the child index is not out of bounds
	assert(index < (unsigned int) Grammar.RuleArray[parent->ReductionRule].SymbolsCount
		&& "ParseChild: index out of bounds !");

	TokenStruct* child = parent->Tokens[index];
	assert(child && "ParseChild: Invalid child");
	// Make sure the child is a rule
	assert(child->ReductionRule >= 0 && "ParseChild must be called on a rule !");

	// Call the rule's subroutine via the RuleJumpTable and return the node
	Nany::Ast::Node* genericNode = RuleJumpTable[child->ReductionRule](child);

	// Cast into the specific wanted node type
	NodeT* specificNode = dynamic_cast<NodeT*>(genericNode);
	assert(specificNode == genericNode && "ParseChild : Invalid dynamic cast !");

	return specificNode;
}


static const wchar_t* GetChildSymbol(TokenStruct* parent, unsigned int index)
{
	assert(parent && "GetChildSymbol: invalid parent");
	// Make sure the child index is not out of bounds
	assert(index < (unsigned int) Grammar.RuleArray[parent->ReductionRule].SymbolsCount
		&& "GetChildSymbol: index out of bounds !");

	TokenStruct* child = parent->Tokens[index];
	assert(child && "GetChildSymbol: invalid child");
	// Make sure the child is a symbol
	assert(child->ReductionRule < 0 && "GetChildSymbol must be called on a symbol !");

	return child->Data;
}




///// Main



// Load input file from disk into memory.
static wchar_t* LoadInputFile(const char *fileName)
{
	// Sanity check.
	if (!fileName || !*fileName)
		return nullptr;

	// Open the file.
	FILE* inFile = fopen(fileName, "rb");
	if (!inFile)
	{
		std::cerr << "Could not open input file: " << fileName << std::endl;
		return nullptr;
	}

	// Get the size of the file.
	struct stat statbuf;
	if (fstat(fileno(inFile), &statbuf) != 0)
	{
		std::cerr << "Could not stat() the input file: " << fileName << std::endl;
		fclose(inFile);
		return NULL;
	}

	// Allocate memory for the input.
	char* buf1 = new char[statbuf.st_size + 1];
	wchar_t* buf2 = new wchar_t[sizeof(wchar_t) * (statbuf.st_size + 1)];
	if (!buf1 || !buf2)
	{
		std::cerr << "Not enough memory to load the file: " << fileName << std::endl;
		fclose(inFile);
		if (buf1 != NULL)
			delete buf1;
		if (buf2 != NULL)
			delete buf2;
		return NULL;
	}

	// Load the file into memory.
	size_t bytesRead = fread(buf1, 1, statbuf.st_size, inFile);
	buf1[bytesRead] = '\0';

	// Close the file.
	fclose(inFile);

	// Exit if there was an error while reading the file.
	if (bytesRead != (size_t)statbuf.st_size)
	{
		std::cerr << "Error while reading input file: " << fileName << std::endl;
		delete buf1;
		delete buf2;
		return nullptr;
	}

	// Convert from ASCII to Unicode.
	for (unsigned long i = 0; i <= bytesRead; i++)
		buf2[i] = buf1[i];
	delete buf1;

	return buf2;
}



static void ShowErrorMessage(TokenStruct* token, int result)
{
	switch (result)
	{
		case PARSELEXICALERROR:
			std::cerr << "Lexical error";
			break;
		case PARSECOMMENTERROR:
			std::cerr << "Comment error";
			break;
		case PARSETOKENERROR:
			std::cerr << "Tokenizer error";
			break;
		case PARSESYNTAXERROR:
			std::cerr << "Syntax error";
			break;
		case PARSEMEMORYERROR:
			std::cerr << "Out of memory";
			break;
	}
	if (token)
		std::cerr << " at line " << token->Line << " column " << token->Column;
	std::cerr << "." << std::endl;

	if (result == PARSELEXICALERROR)
	{
		if (token->Data != NULL)
		{
			wchar_t s1[BUFSIZ];
			ReadableString(token->Data, s1, BUFSIZ);
			std::wcerr << L"The grammar does not specify what to do with '" << s1 << L"'." << std::endl;
		}
		else
		{
			std::cerr << "The grammar does not specify what to do." << std::endl;
		}
	}
	if (result == PARSETOKENERROR)
	{
		std::cerr << "The tokenizer returned a non-terminal." << std::endl;
	}
	if (result == PARSECOMMENTERROR)
	{
		std::cerr << "The comment has no end, it was started but not finished." << std::endl;
	}
	if (result == PARSESYNTAXERROR)
	{
		if (token->Data)
		{
			wchar_t s1[BUFSIZ];
			ReadableString(token->Data, s1, BUFSIZ);
			std::wcerr << L"Encountered '" << s1 << L"', but expected ";
		}
		else
		{
			std::cerr << "Expected ";
		}

		for (unsigned int i = 0; i < (unsigned int) Grammar.LalrArray[token->Symbol].ActionCount; ++i)
		{
			unsigned int symbol = (unsigned int) Grammar.LalrArray[token->Symbol].Actions[i].Entry;
			if (Grammar.SymbolArray[symbol].Kind == SYMBOLTERMINAL)
			{
				if (i > 0)
				{
					std::cerr << ", ";
					if (i + 2 >= (unsigned int) Grammar.LalrArray[token->Symbol].ActionCount)
						std::cerr << "or ";
				}
				std::wcerr << L'\'' << Grammar.SymbolArray[symbol].Name << L'\'';
			}
		}
		std::cerr << "." << std::endl;
	}
}



Nany::Ast::Node* parseFile(const char* filePath)
{
	Nany::Ast::Node* tree = nullptr;

	// Load the inputfile into memory.
	wchar_t* inputBuf = LoadInputFile(filePath);
	if (!inputBuf)
	{
		std::cerr << "\"" << filePath << "\" could not be opened." << std::endl;
		return tree;
	}


	// Run the Parser.
	TokenStruct* token;
	int parseResult = Parse(inputBuf, wcslen(inputBuf), TRIMREDUCTIONS, &token);

	// Interpret the results.
	if (parseResult != PARSEACCEPT)
	{
		ShowErrorMessage(token, parseResult);
	}
	else
	{
		// Start execution by calling the subroutine of the first Token on
		// the TokenStack. It's the "Start Symbol" that is defined in the
		// grammar.
		tree = RuleJumpTable[token->ReductionRule](token);
	}

	// Cleanup.
	DeleteTokens(token);
	delete inputBuf;
	return tree;
}


